{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "interstate-stewart",
   "metadata": {},
   "source": [
    "# Task 1: Instructions\n",
    "\n",
    "Print out the raw data in the Git log file to show the available format.\n",
    "\n",
    "- Print out the content of the sample file `git_log_excerpt.csv`.\n",
    "\n",
    "## Good to know\n",
    "\n",
    "This Project requires that you know your way around Python and Pandas. We recommend that you have complete these DataCamp courses before doing this project:\n",
    "\n",
    "- [Intermediate Python for Data Science](https://www.datacamp.com/courses/intermediate-python-for-data-science).\n",
    "- [Data Manipulation with pandas](https://www.datacamp.com/courses/data-manipulation-with-pandas).\n",
    "- [Manipulating Time Series Data in Python](https://www.datacamp.com/courses/manipulating-time-series-data-in-python)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-flavor",
   "metadata": {},
   "source": [
    "# Task 2: Instructions\n",
    "\n",
    "Read in the Linux Git log file with Pandas.\n",
    "\n",
    "- Load in the `pandas` module as `pd`.\n",
    "- Read in the log file `git_log.gz`. Name the 1st column \"`timestamp`\" and the 2nd column \"`author`\".\n",
    "- Assign the resulting DataFrame to `git_log`.\n",
    "- Print out the first five rows of `git_log`.\n",
    "- The `pandas` method `read_csv` can read a CSV file compressed in a `gz` file. You will have to specify the `sep`, `encoding`, `header`, and `names` arguments to `read_csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taken-chambers",
   "metadata": {},
   "source": [
    "# Task 3: Instructions\n",
    "\n",
    "Gather some basic metrics about Linux's Git repository.\n",
    "\n",
    "- Count the number of commits in `git_log`.\n",
    "- Count the number of all contributing authors. Leave out the entries that don't have an author at all.\n",
    "\n",
    "Here, use some basic functions of Python, Pandas' `DataFrame` and `Series` to count values and to remove missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joined-caribbean",
   "metadata": {},
   "source": [
    "# Task 4: Instructions\n",
    "\n",
    "List the ten authors that made the most commits.\n",
    "\n",
    "- Count how often each author occurs in `git_log`, pick out the top ten authors, and assign the result to `top_10_authors`.\n",
    "\n",
    "In this task, the result that is stored in `top_10_authors` has to be a `Series` or a `DataFrame` that includes the authors and the number of commits that each author has made."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-gospel",
   "metadata": {},
   "source": [
    "# Task 5: Instructions\n",
    "\n",
    "Transform the numbers in timestamp to time series-based data type.\n",
    "\n",
    "- Convert the `timestamp` column to a Pandas' `Timestamp` type.\n",
    "- Look at a summary of the converted `timestamp` column to check if the conversion was successful and if the boundary values make sense.\n",
    "\n",
    "Here is the [official Pandas documentation for how to convert these type of time stamps](http://pandas-docs.github.io/pandas-docs-travis/timeseries.html#epoch-timestamps) (called _epoch_ time stamps) to `Timestamp`. Be sure to set the right `unit` of time (in our case: seconds) to the date conversion method. To summarize the resulting `Timestamp` column you could use the `describe()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-concern",
   "metadata": {},
   "source": [
    "# Task 6: Instructions\n",
    "\n",
    "Determine a right time period and keep only those commits within this time period.\n",
    "\n",
    "- Pick a reasonable _first_ timestamp and assign it to `first_commit_timestamp`.\n",
    "- Pick a reasonable _last_ timestamp for this dataset from late 2017 and assign it to `last_commit_timestamp`.\n",
    "- Create a new `DataFrame` called `corrected_log`.\n",
    "- Use `describe()` on `corrected_log['timestamp']` to check the data.\n",
    "\n",
    "A possible valid time period:\n",
    "\n",
    "- The _first_ reasonable entry is the first commit from Linus Torvalds.\n",
    "- Every commit before the year 2018 would be a reasonable _last_ timestamp."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mounted-guarantee",
   "metadata": {},
   "source": [
    "# Task 7: Instructions\n",
    "\n",
    "Count the number of commits of the `corrected_log` for each year:\n",
    "\n",
    "- Create a new `DataFrame` called `commits_per_year` that sums up all commits annually, starting at January 1st.\n",
    "- Show the first five rows of the `DataFrame`.\n",
    "\n",
    "There are many ways to accomplish this with Pandas. Use the `groupby` method with the utility function `Grouper` to group by year:\n",
    "\n",
    "```\n",
    "my_data_frame.groupby(pd.Grouper(key='my_timestamp_column',\n",
    "                                 freq='AS'))\n",
    "```\n",
    "\n",
    "Here, `freq='AS'` makes `groupby` group by year using the 1st of January as starting day."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-cooking",
   "metadata": {},
   "source": [
    "# Task 8: Instructions\n",
    "\n",
    "Visualize the yearly counts using a suitable plot.\n",
    "\n",
    "- Plot `commits_per_year` using the `pandas` `plot` method.\n",
    "- Add a suitable `title`.\n",
    "- Turn the `legend` off.\n",
    "\n",
    "The `plot` method in `pandas` takes many options that allow you to customize your plot. Here is the [official documentation for `plot` for Series](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.plot.html). That documentation contains a lot of info, but the arguments you might want to add here are `kind`, `title`, and `legend`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-figure",
   "metadata": {},
   "source": [
    "# Task 9: Instructions\n",
    "\n",
    "Thanks for doing the project! As a last task:\n",
    "\n",
    "- Set `year_with_most_commits` to the year with the most commits to Linux (as of autumn 2017).\n",
    "\n",
    "## Further Reading\n",
    "\n",
    "If you are more interested in mining software repositories, take a look at the following books:\n",
    "\n",
    "- Adam Tornhill: Software X-Ray. Pragmatic Programmers, 2018.\n",
    "- Christian Bird, Tim Menzies, Thomas Zimmermann: The Art and Science of Analyzing Software Data. Morgan Kaufmann, 2015.\n",
    "- Tim Menzies, Laurie Williams, Thomas Zimmermann: Perspectives on Data Science for Software Engineering. Morgan Kaufmann, 2016."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
